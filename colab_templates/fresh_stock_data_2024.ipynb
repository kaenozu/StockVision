{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fresh_stock_data_2024"
   },
   "source": [
    "# StockVision - æ–°é®®ãªæ ªä¾¡ãƒ‡ãƒ¼ã‚¿å–å¾— (2024å¹´1æœˆã€œç¾åœ¨)\n",
    "\n",
    "ã“ã®Notebookã¯æ­£ç¢ºãªæ—¥æœ¬æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€StockVisionã‚·ã‚¹ãƒ†ãƒ ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆå¯èƒ½ãªCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã™ã€‚\n",
    "\n",
    "## å–å¾—æœŸé–“\n",
    "- **é–‹å§‹**: 2024å¹´1æœˆ1æ—¥\n",
    "- **çµ‚äº†**: ç¾åœ¨\n",
    "- **å¯¾è±¡**: ä¸»è¦æ—¥æœ¬æ ª10éŠ˜æŸ„\n",
    "\n",
    "## æ”¹å–„ç‚¹\n",
    "- ã‚ˆã‚Šé•·æœŸé–“ã®ãƒ‡ãƒ¼ã‚¿\n",
    "- ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯\n",
    "- ç•°å¸¸å€¤æ¤œå‡º\n",
    "- æ­£ç¢ºãªä¾¡æ ¼æƒ…å ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_packages"
   },
   "outputs": [],
   "source": [
    "# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
    "!pip install yfinance pandas numpy matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_libraries"
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"ãƒ©ã‚¤ãƒ–ãƒ©ãƒªèª­ã¿è¾¼ã¿å®Œäº†\")\n",
    "print(f\"ç¾åœ¨æ™‚åˆ»: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "define_stock_list"
   },
   "outputs": [],
   "source": [
    "# ä¸»è¦æ—¥æœ¬æ ªéŠ˜æŸ„ãƒªã‚¹ãƒˆ\n",
    "stocks = {\n",
    "    '7203.T': 'Toyota Motor Corporation',\n",
    "    '9984.T': 'SoftBank Group Corp.',\n",
    "    '6758.T': 'Sony Group Corporation',\n",
    "    '7974.T': 'Nintendo Co., Ltd.',\n",
    "    '6861.T': 'Keyence Corporation',\n",
    "    '9983.T': 'Fast Retailing Co., Ltd.',\n",
    "    '4689.T': 'Yahoo Japan Corporation',\n",
    "    '6367.T': 'Daikin Industries, Ltd.',\n",
    "    '4502.T': 'Takeda Pharmaceutical Company Limited',\n",
    "    '8267.T': 'AEON Co., Ltd.'\n",
    "}\n",
    "\n",
    "print(f\"å¯¾è±¡éŠ˜æŸ„æ•°: {len(stocks)}\")\n",
    "for code, name in stocks.items():\n",
    "    print(f\"  {code}: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_date_range"
   },
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿å–å¾—æœŸé–“ã®è¨­å®š\n",
    "start_date = '2024-01-01'\n",
    "end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "print(\"ãƒ‡ãƒ¼ã‚¿å–å¾—æœŸé–“:\")\n",
    "print(f\"  é–‹å§‹æ—¥: {start_date}\")\n",
    "print(f\"  çµ‚äº†æ—¥: {end_date}\")\n",
    "\n",
    "# æœŸé–“ã®æ—¥æ•°è¨ˆç®—\n",
    "start_dt = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "end_dt = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "days_diff = (end_dt - start_dt).days\n",
    "print(f\"  æœŸé–“: {days_diff}æ—¥é–“\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fetch_stock_data"
   },
   "outputs": [],
   "source": [
    "# æ ªä¾¡ãƒ‡ãƒ¼ã‚¿å–å¾—é–¢æ•°\n",
    "def fetch_stock_data(symbol, start, end, company_name):\n",
    "    \"\"\"æŒ‡å®šã•ã‚ŒãŸéŠ˜æŸ„ã®æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—\"\"\"\n",
    "    try:\n",
    "        print(f\"å–å¾—ä¸­: {symbol} ({company_name})\")\n",
    "        \n",
    "        # yfinanceã§ãƒ‡ãƒ¼ã‚¿å–å¾—\n",
    "        ticker = yf.Ticker(symbol)\n",
    "        hist = ticker.history(start=start, end=end)\n",
    "        \n",
    "        if hist.empty:\n",
    "            print(f\"  âš ï¸ ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {symbol}\")\n",
    "            return None\n",
    "        \n",
    "        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ æ•´å½¢\n",
    "        df = hist.reset_index()\n",
    "        df['Stock_Code'] = symbol.replace('.T', '')  # .Tã‚’é™¤å»\n",
    "        df['Company_Name'] = company_name\n",
    "        \n",
    "        # ã‚«ãƒ©ãƒ åã‚’çµ±ä¸€\n",
    "        df = df.rename(columns={\n",
    "            'Date': 'Date',\n",
    "            'Open': 'Open',\n",
    "            'High': 'High', \n",
    "            'Low': 'Low',\n",
    "            'Close': 'Close',\n",
    "            'Volume': 'Volume'\n",
    "        })\n",
    "        \n",
    "        # å¿…è¦ãªã‚«ãƒ©ãƒ ã®ã¿é¸æŠ\n",
    "        df = df[['Stock_Code', 'Company_Name', 'Date', 'Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "        \n",
    "        # ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯\n",
    "        null_count = df.isnull().sum().sum()\n",
    "        if null_count > 0:\n",
    "            print(f\"  âš ï¸ æ¬ æå€¤ã‚ã‚Š: {null_count}ä»¶\")\n",
    "            df = df.dropna()  # æ¬ æå€¤å‰Šé™¤\n",
    "        \n",
    "        # ä¾¡æ ¼ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯\n",
    "        min_price = df[['Open', 'High', 'Low', 'Close']].min().min()\n",
    "        max_price = df[['Open', 'High', 'Low', 'Close']].max().max()\n",
    "        \n",
    "        if min_price <= 0:\n",
    "            print(f\"  âš ï¸ ç•°å¸¸ãªä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚ã‚Š (æœ€å°å€¤: {min_price})\")\n",
    "            df = df[(df[['Open', 'High', 'Low', 'Close']] > 0).all(axis=1)]\n",
    "        \n",
    "        print(f\"  âœ… å–å¾—æˆåŠŸ: {len(df)}ä»¶ (ä¾¡æ ¼ç¯„å›²: {min_price:.2f}ã€œ{max_price:.2f}å††)\")\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ ã‚¨ãƒ©ãƒ¼: {symbol} - {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# å…¨éŠ˜æŸ„ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—\n",
    "all_data = []\n",
    "success_count = 0\n",
    "total_records = 0\n",
    "\n",
    "print(\"\\n=== æ ªä¾¡ãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹ ===\")\n",
    "for symbol, company_name in stocks.items():\n",
    "    data = fetch_stock_data(symbol, start_date, end_date, company_name)\n",
    "    if data is not None:\n",
    "        all_data.append(data)\n",
    "        success_count += 1\n",
    "        total_records += len(data)\n",
    "\n",
    "print(\"\\n=== å–å¾—çµæœ ===\")\n",
    "print(f\"æˆåŠŸ: {success_count}/{len(stocks)} éŠ˜æŸ„\")\n",
    "print(f\"ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {total_records:,}ä»¶\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "combine_and_validate"
   },
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿ã®çµåˆã¨æ¤œè¨¼\n",
    "if all_data:\n",
    "    # å…¨ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    print(\"=== ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ ===\")\n",
    "    print(f\"ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(combined_df):,}\")\n",
    "    print(f\"éŠ˜æŸ„æ•°: {combined_df['Stock_Code'].nunique()}\")\n",
    "    print(f\"æœŸé–“: {combined_df['Date'].min()} ã€œ {combined_df['Date'].max()}\")\n",
    "    \n",
    "    # å„éŠ˜æŸ„ã®çµ±è¨ˆ\n",
    "    print(\"\\n=== éŠ˜æŸ„åˆ¥ãƒ‡ãƒ¼ã‚¿æ•° ===\")\n",
    "    stock_counts = combined_df.groupby(['Stock_Code', 'Company_Name']).size().reset_index(name='Records')\n",
    "    for _, row in stock_counts.iterrows():\n",
    "        print(f\"  {row['Stock_Code']}: {row['Records']:,}ä»¶ ({row['Company_Name']})\")\n",
    "    \n",
    "    # ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯\n",
    "    print(\"\\n=== ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯ ===\")\n",
    "    \n",
    "    # é‡è¤‡ãƒã‚§ãƒƒã‚¯\n",
    "    duplicates = combined_df.duplicated(['Stock_Code', 'Date']).sum()\n",
    "    print(f\"é‡è¤‡ãƒ¬ã‚³ãƒ¼ãƒ‰: {duplicates}ä»¶\")\n",
    "    \n",
    "    # ä¾¡æ ¼ç•°å¸¸å€¤ãƒã‚§ãƒƒã‚¯\n",
    "    for stock_code in combined_df['Stock_Code'].unique():\n",
    "        stock_data = combined_df[combined_df['Stock_Code'] == stock_code]\n",
    "        \n",
    "        # ä¾¡æ ¼ã®çµ±è¨ˆ\n",
    "        close_prices = stock_data['Close']\n",
    "        mean_price = close_prices.mean()\n",
    "        std_price = close_prices.std()\n",
    "        \n",
    "        # 3Ïƒã‚’è¶…ãˆã‚‹ç•°å¸¸å€¤æ¤œå‡º\n",
    "        anomalies = stock_data[\n",
    "            (stock_data['Close'] < mean_price - 3 * std_price) |\n",
    "            (stock_data['Close'] > mean_price + 3 * std_price)\n",
    "        ]\n",
    "        \n",
    "        if len(anomalies) > 0:\n",
    "            print(f\"  {stock_code}: {len(anomalies)}ä»¶ã®ç•°å¸¸å€¤å€™è£œ\")\n",
    "            for _, anomaly in anomalies.iterrows():\n",
    "                z_score = (anomaly['Close'] - mean_price) / std_price\n",
    "                print(f\"    {anomaly['Date'].strftime('%Y-%m-%d')}: {anomaly['Close']:.2f}å†† (Z={z_score:.2f})\")\n",
    "        else:\n",
    "            print(f\"  {stock_code}: ç•°å¸¸å€¤ãªã— (å¹³å‡: {mean_price:.2f}å††)\")\n",
    "    \n",
    "    print(\"\\nâœ… ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼å®Œäº†\")\n",
    "else:\n",
    "    print(\"âŒ ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_visualization"
   },
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–\n",
    "if all_data:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('æ ªä¾¡ãƒ‡ãƒ¼ã‚¿æ¦‚è¦ (2024å¹´1æœˆã€œç¾åœ¨)', fontsize=16)\n",
    "    \n",
    "    # 1. å„éŠ˜æŸ„ã®çµ‚å€¤æ¨ç§»\n",
    "    ax1 = axes[0, 0]\n",
    "    for stock_code in combined_df['Stock_Code'].unique()[:5]:  # ä¸Šä½5éŠ˜æŸ„\n",
    "        stock_data = combined_df[combined_df['Stock_Code'] == stock_code]\n",
    "        ax1.plot(pd.to_datetime(stock_data['Date']), stock_data['Close'], \n",
    "                label=stock_code, alpha=0.7)\n",
    "    ax1.set_title('çµ‚å€¤æ¨ç§» (ä¸»è¦5éŠ˜æŸ„)')\n",
    "    ax1.set_xlabel('æ—¥ä»˜')\n",
    "    ax1.set_ylabel('ä¾¡æ ¼ (å††)')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿æ•°ã®åˆ†å¸ƒ\n",
    "    ax2 = axes[0, 1]\n",
    "    daily_counts = combined_df.groupby('Date').size()\n",
    "    ax2.hist(daily_counts, bins=20, alpha=0.7, color='skyblue')\n",
    "    ax2.set_title('æ—¥åˆ¥ãƒ‡ãƒ¼ã‚¿æ•°åˆ†å¸ƒ')\n",
    "    ax2.set_xlabel('1æ—¥ã‚ãŸã‚Šã®ãƒ‡ãƒ¼ã‚¿æ•°')\n",
    "    ax2.set_ylabel('æ—¥æ•°')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. éŠ˜æŸ„åˆ¥ãƒ‡ãƒ¼ã‚¿æ•°\n",
    "    ax3 = axes[1, 0]\n",
    "    stock_counts = combined_df['Stock_Code'].value_counts()\n",
    "    stock_counts.plot(kind='bar', ax=ax3, color='lightgreen')\n",
    "    ax3.set_title('éŠ˜æŸ„åˆ¥ãƒ‡ãƒ¼ã‚¿æ•°')\n",
    "    ax3.set_xlabel('éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰')\n",
    "    ax3.set_ylabel('ãƒ‡ãƒ¼ã‚¿æ•°')\n",
    "    ax3.tick_params(axis='x', rotation=45)\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. å‡ºæ¥é«˜åˆ†å¸ƒ\n",
    "    ax4 = axes[1, 1]\n",
    "    ax4.hist(np.log10(combined_df['Volume'] + 1), bins=30, alpha=0.7, color='orange')\n",
    "    ax4.set_title('å‡ºæ¥é«˜åˆ†å¸ƒ (log10)')\n",
    "    ax4.set_xlabel('log10(å‡ºæ¥é«˜)')\n",
    "    ax4.set_ylabel('é »åº¦')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"ğŸ“Š ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–å®Œäº†\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "export_csv"
   },
   "outputs": [],
   "source": [
    "# CSVãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›\n",
    "if all_data:\n",
    "    # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç¾åœ¨æ—¥æ™‚ã§ä½œæˆ\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    filename = f'fresh_stock_data_2024_{timestamp}.csv'\n",
    "    \n",
    "    # CSVå‡ºåŠ›\n",
    "    combined_df.to_csv(filename, index=False, encoding='utf-8')\n",
    "    \n",
    "    print(\"=== CSVå‡ºåŠ›å®Œäº† ===\")\n",
    "    print(f\"ãƒ•ã‚¡ã‚¤ãƒ«å: {filename}\")\n",
    "    print(f\"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {len(combined_df):,} ãƒ¬ã‚³ãƒ¼ãƒ‰\")\n",
    "    print(f\"ã‚«ãƒ©ãƒ : {list(combined_df.columns)}\")\n",
    "    \n",
    "    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º\n",
    "    print(\"\\n=== ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ (æœ€åˆã®5è¡Œ) ===\")\n",
    "    print(combined_df.head())\n",
    "    \n",
    "    print(\"\\nâœ… å‡¦ç†å®Œäº†ï¼\")\n",
    "    print(\"\\nğŸ“‹ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:\")\n",
    "    print(\"1. CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’Google Driveã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\")\n",
    "    print(\"2. å…±æœ‰ãƒªãƒ³ã‚¯ã‚’å–å¾—\")\n",
    "    print(\"3. StockVisionã§ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Ÿè¡Œ\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ CSVã®å‡ºåŠ›ã«å¤±æ•—ã—ã¾ã—ãŸ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_file"
   },
   "outputs": [],
   "source": [
    "# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (Google Colab)\n",
    "try:\n",
    "    from google.colab import files\n",
    "    if 'filename' in locals():\n",
    "        files.download(filename)\n",
    "        print(f\"ğŸ“¥ {filename} ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ\")\n",
    "    else:\n",
    "        print(\"âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“\")\n",
    "except ImportError:\n",
    "    print(\"â„¹ï¸ Google Colabç’°å¢ƒã§ã¯ã‚ã‚Šã¾ã›ã‚“ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒï¼‰\")\n",
    "    print(f\"ãƒ•ã‚¡ã‚¤ãƒ«ã¯ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ: {filename if 'filename' in locals() else 'æœªä½œæˆ'}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}